***Модифицировать программу, перемножащую матрицы таким образом, чтобы она делала это параллельно с помощью MPI. Запустить эту версию на суперкомпьютере Суперкомпьютере "Сергей Королев".
В этой работе мы рассмотрим параллельное программирование с помощью MPI и сравним его выполнение на супер компьютере Сергей Королев и на моем ноутбуке c 11th Gen Intel(R) Core(TM) i5-12500h @ 3.00GHz.***

*Результаты замеров последовательного выполнения:*
| Размер перемножаемых матриц	| Время, с |
| --- | --- |
750х100 |	0,412
750х200	| 0,844
750х300 |	1,256
750х400	| 1,757
750х500	| 2,212
750х600	| 2,814
750х750	| 3,723

*Результаты замеров параллеьного выполнения MPI на моем ноутбуке, 4 ядра:*
| Размер перемножаемых матриц	| Время, с |
| --- | --- |
750х100 |	0,181
750х200	| 0,363
750х300	| 0,562
750х400	| 0,757
750х500	| 0,936
750х600	| 1,127
750х750	| 1,465

*Результаты замеров параллельного выполнения MPI на супер компьютере с разным количеством ядер:*
![image](https://github.com/user-attachments/assets/01efc485-dc46-4f6c-955e-ed8f0d7360ce)


![image](https://github.com/user-attachments/assets/701e6dcc-ed93-455a-b4d4-324db8b0a331)

**Вывод: Можно заключить, что применение технологии MPI на суперкомпьютере Сергей Королев значительно повышает производительность. В отдельных вычислениях время выполнения сокращается в восемь раз. Применяя технологию MPI и распределяя нагрузку на кластере, можно добиться более быстрых результатов**
